# Multilingual Diabetes Management Chatbot using RAG
A retrieval-augmented, multilingual healthcare chatbot designed to provide diabetes-related guidance using trusted medical sources.
The system combines LLMs, semantic retrieval, empathetic prompting, and multilingual translation to generate safe, context-aware, and supportive responses for patient-style queries.
This is a graduate-level NLP project completed as part of the Natural Language Processing course at the University at Buffalo.
___

# Project Motivation
Diabetes management requires continuous education, lifestyle awareness, and emotional support.
However, access to personalized, multilingual, and empathetic medical guidance is limitedâ€”especially in low-resource settings.
This project explores how large language models (LLMs) combined with Retrieval-Augmented Generation (RAG) can help bridge this gap by:
Grounding responses in authoritative medical guidelines
Supporting multiple languages
Avoiding unsafe medical advice
Adapting responses to patient context (age, glucose level, symptoms, medications)
___

# System Overview
The chatbot architecture consists of four main components:
Medical Knowledge Base (RAG)
WHO and ADA diabetes guidelines
Chunked and indexed using semantic embeddings
Language Model
BLOOMZ-3B, an instruction-tuned multilingual LLM
Retrieval-Augmented Generation
Relevant medical passages are retrieved using FAISS
Retrieved context is injected into the prompt before generation
Empathetic & Personalized Prompting
Patient attributes (age, glucose level, symptoms, medications)
Safety-aware response design to avoid unsafe recommendations
___

# Datasets Used
1. Medical Knowledge Sources (RAG Corpus)
WHO â€“ Management of Diabetes Mellitus: Standards of Care
ADA â€“ Standards of Care in Diabetes (2024)
2. Training & Evaluation Data
MedQuAD â€“ Medical questionâ€“answer pairs (diabetes-filtered)
MedicationQA (TrueHealth) â€“ Drug-related Q&A
MedQA (USMLE-style) â€“ Clinical reasoning QA
MedDialog-EN â€“ Multi-turn medical dialogues
Custom Synthetic QA â€“ Author-created diabetes scenarios
All datasets were normalized into a JSONL conversational format suitable for instruction tuning and evaluation.
___

# Methodology
ðŸ”¹ Fine-Tuning
Framework: Hugging Face Transformers
Technique: Parameter-Efficient Fine-Tuning (LoRA)
Model: BLOOMZ-3B
Precision: FP16
Training Style: Instruction-based conversational formatting
ðŸ”¹ Retrieval-Augmented Generation (RAG)
Embedding model: all-MiniLM-L6-v2
Index: FAISS
Top-k retrieval: 8 passages
Retrieved medical context appended to the prompt before generation
ðŸ”¹ Multilingual Support
Translation pipelines using Helsinki-NLP Opus-MT
Supported languages:
English
Spanish
French
ðŸ”¹ Safety & Personalization
Conservative response design (no dosage prescriptions)
Patient profile conditioning:
Age
Glucose level
Symptoms
Medications
___

# Evaluation
The system was evaluated on realistic patient-style queries across multiple languages.
Quantitative Metrics
BLEU: 0.00
(Expected for open-ended medical dialogue)
BERTScore (F1): 0.7873
(Indicates semantic relevance despite lexical variation)
Qualitative Evaluation
Tested on English, Spanish, and French patient profiles
Demonstrated:
Strong multilingual understanding
Safety-first behavior
Context-aware responses
Conservative handling of medical advice
Full experimental analysis and UI screenshots are available in the project report
NLP Report - Final
___


# Example Capabilities
Answers lifestyle and diet questions safely
Avoids unsafe medical recommendations
Adapts tone and content based on patient context
Handles multilingual input seamlessly
Grounds responses in authoritative medical documents
___

# Technology Stack
Python
PyTorch
Hugging Face Transformers
PEFT / LoRA
FAISS
Sentence Transformers
BLOOMZ-3B
Opus-MT (Multilingual Translation)
Jupyter Notebook
___

# Repository Structure
â”œâ”€â”€ datasets_used/
â”‚   â”œâ”€â”€ WHO.pdf
â”‚   â”œâ”€â”€ ADA.pdf
â”‚   â”œâ”€â”€ train.jsonl
â”‚   â”œâ”€â”€ dev.jsonl
â”‚   â”œâ”€â”€ test.jsonl
â”‚   â”œâ”€â”€ US_qbank.jsonl
â”‚   â””â”€â”€ medDataset_processed.csv
â”‚
â”œâ”€â”€ part1_data_prepor.ipynb
â”‚   â””â”€â”€ Data preprocessing, dataset construction, embedding & retrieval
â”‚
â”œâ”€â”€ NLP_Milestone3_part2.ipynb
â”‚   â””â”€â”€ RAG pipeline, multilingual chatbot inference, evaluation
â”‚
â”œâ”€â”€ Report - Final.pdf
â”‚   â””â”€â”€ Full methodology, experiments, results, and discussion
â”‚
â”œâ”€â”€ Video Demo.mp4
â”‚   â””â”€â”€ End-to-end chatbot demonstration
â”‚
â””â”€â”€ README.md
___
# Authors
Kanisha Raja
M.S. Artificial Intelligence
University at Buffalo
Sai Deshith Sandakacharla
M.S. Artificial Intelligence
University at Buffalo

# Future Work
Multi-turn dialogue memory
Improved empathetic response modeling
Reinforcement learning from human feedback (RLHF)
Better dialogue-specific evaluation metrics
Expanded language support
